{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d3ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9e62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "path_training = \"Training and Testing Sets/UNSW_NB15_training-set.csv\"\n",
    "path_testing = \"Training and Testing Sets/UNSW_NB15_testing-set.csv\"\n",
    "df_train = pd.read_csv(path_training)\n",
    "df_test = pd.read_csv(path_testing)\n",
    "\n",
    "# Convert categorical features to float\n",
    "categorical_features = ['proto', 'service', 'state', 'attack_cat']\n",
    "for feature in categorical_features:\n",
    "    df_train[feature] = df_train[feature].astype('category').cat.codes\n",
    "    df_test[feature] = df_test[feature].astype('category').cat.codes\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Directement MinMaxScaler en [-1, 1]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "df_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_train.drop(columns=['label'])), \n",
    "    columns=df_train.columns.drop('label')\n",
    ")\n",
    "df_train_scaled['label'] = df_train['label'].values\n",
    "\n",
    "df_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(df_test.drop(columns=['label'])), \n",
    "    columns=df_test.columns.drop('label')\n",
    ")\n",
    "df_test_scaled['label'] = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ced048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important features based on correlation with label:\n",
      " label                1.000000\n",
      "id                   0.727173\n",
      "sttl                 0.692741\n",
      "ct_state_ttl         0.577704\n",
      "state                0.497685\n",
      "dload                0.393739\n",
      "ct_dst_sport_ltm     0.357213\n",
      "dmean                0.341806\n",
      "rate                 0.337979\n",
      "swin                 0.333633\n",
      "dwin                 0.319626\n",
      "ct_src_dport_ltm     0.305579\n",
      "ct_dst_src_ltm       0.303855\n",
      "stcpb                0.255006\n",
      "dtcpb                0.250340\n",
      "ct_src_ltm           0.238225\n",
      "ct_dst_ltm           0.229887\n",
      "ct_srv_src           0.229044\n",
      "ct_srv_dst           0.228046\n",
      "is_sm_ips_ports      0.184679\n",
      "sload                0.182870\n",
      "sinpkt               0.176110\n",
      "dpkts                0.118591\n",
      "ackdat               0.097364\n",
      "dttl                 0.095049\n",
      "dloss                0.094685\n",
      "tcprtt               0.081584\n",
      "dbytes               0.076871\n",
      "djit                 0.060870\n",
      "synack               0.058299\n",
      "spkts                0.052178\n",
      "dur                  0.036175\n",
      "service              0.035052\n",
      "dinpkt               0.022887\n",
      "response_body_len    0.021361\n",
      "proto                0.020267\n",
      "sbytes               0.018576\n",
      "ct_flw_http_mthd     0.015800\n",
      "is_ftp_login         0.011055\n",
      "ct_ftp_cmd           0.011055\n",
      "trans_depth          0.010801\n",
      "smean                0.010798\n",
      "sjit                 0.007069\n",
      "sloss                0.000640\n",
      "Name: label, dtype: float64\n",
      "Top 20 features selected for training:\n",
      " ['id', 'sttl', 'ct_state_ttl', 'state', 'dload', 'ct_dst_sport_ltm', 'dmean', 'rate', 'swin', 'dwin', 'ct_src_dport_ltm', 'ct_dst_src_ltm', 'stcpb', 'dtcpb', 'ct_src_ltm', 'ct_dst_ltm', 'ct_srv_src', 'ct_srv_dst', 'is_sm_ips_ports', 'sload']\n",
      "X_train shape: (175341, 20)\n",
      "y_train shape: (175341,)\n",
      "X_test shape: (82332, 20)\n",
      "y_test shape: (82332,)\n",
      "X_train after scaling shape: (175341, 20)\n",
      "X_test after scaling shape: (82332, 20)\n"
     ]
    }
   ],
   "source": [
    "# Determine important features\n",
    "# Based on correlation with the label, we can select features with high absolute correlation values\n",
    "df_train = df_train.drop(\"attack_cat\",axis=1)\n",
    "df_test = df_test.drop(\"attack_cat\",axis=1)\n",
    "corr_matrix = df_train.corr()\n",
    "important_features = corr_matrix['label'].abs().sort_values(ascending=False)\n",
    "print(\"Important features based on correlation with label:\\n\", important_features)\n",
    "\n",
    "# Select top N features (excluding the label itself)\n",
    "N = 20\n",
    "top_features = important_features.index[1:N+1].tolist()\n",
    "print(\"Top {} features selected for training:\\n\".format(N), top_features)\n",
    "\n",
    "# Prepare data for training\n",
    "X_train = df_train[top_features]\n",
    "y_train = df_train['label']\n",
    "X_test = df_test[top_features]\n",
    "y_test = df_test['label']\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Normalize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"X_train after scaling shape:\", X_train.shape)\n",
    "print(\"X_test after scaling shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149e33f",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4315d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5135\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4694    0.6326    0.5389     37000\n",
      "           1     0.5813    0.4164    0.4852     45332\n",
      "\n",
      "    accuracy                         0.5135     82332\n",
      "   macro avg     0.5254    0.5245    0.5121     82332\n",
      "weighted avg     0.5310    0.5135    0.5093     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Simple feedforward neural network\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    random_state=42,\n",
    "    max_iter=200,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c38589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading synthetic file: C:\\Users\\phasi\\Documents\\GitHub\\Final-Project-GAN-Cybersecurity\\synthetic_saves\\synthetic_data.csv\n",
      "Synthetic shape: (10000, 21)\n",
      "Synthetic columns preview: ['id', 'sttl', 'ct_state_ttl', 'state', 'dload', 'ct_dst_sport_ltm', 'dmean', 'rate', 'swin', 'dwin']\n",
      "Accuracy of real-trained classifier on synthetic data: 0.5723\n",
      "Accuracy of synthetic-trained classifier evaluated on real test: 0.6958\n",
      "Accuracy after augmenting real training with synthetic (eval on real test): 0.5516\n",
      "\n",
      "Summary of accuracies:\n",
      "- Real-trained clf on real test (previously computed): 0.5135\n",
      "- Real-trained clf on synthetic data: 0.5723\n",
      "- Trained on synthetic only, eval on real test: 0.6958\n",
      "- Trained on real+synthetic (augmented), eval on real test: 0.5516\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Load synthetic data and compare classifier performance\n",
    "\n",
    "synth_dir = r\"C:\\Users\\phasi\\Documents\\GitHub\\Final-Project-GAN-Cybersecurity\\synthetic_saves\"\n",
    "\n",
    "# find a plausible synthetic file (csv, pkl, npy)\n",
    "candidates = glob.glob(os.path.join(synth_dir, \"*.csv\")) + \\\n",
    "             glob.glob(os.path.join(synth_dir, \"*.pkl\")) + \\\n",
    "             glob.glob(os.path.join(synth_dir, \"*.npy\"))\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(f\"No synthetic files found in {synth_dir}. Expected .csv/.pkl/.npy\")\n",
    "\n",
    "synth_path = candidates[0]\n",
    "print(\"Loading synthetic file:\", synth_path)\n",
    "\n",
    "# load depending on extension\n",
    "if synth_path.lower().endswith(\".csv\"):\n",
    "    df_synth = pd.read_csv(synth_path)\n",
    "elif synth_path.lower().endswith(\".pkl\"):\n",
    "    df_synth = pd.read_pickle(synth_path)\n",
    "elif synth_path.lower().endswith(\".npy\"):\n",
    "    arr = np.load(synth_path, allow_pickle=True)\n",
    "    # if it's saved as structured array or dict-like\n",
    "    if isinstance(arr, np.ndarray) and arr.dtype.names:\n",
    "        df_synth = pd.DataFrame(arr)\n",
    "    else:\n",
    "        # try to handle dict-like saved numpy (fallback)\n",
    "        try:\n",
    "            df_synth = pd.DataFrame(arr.tolist())\n",
    "        except Exception:\n",
    "            raise ValueError(\"Cannot convert .npy content to DataFrame automatically.\")\n",
    "else:\n",
    "    raise ValueError(\"Unsupported synthetic file format.\")\n",
    "\n",
    "print(\"Synthetic shape:\", df_synth.shape)\n",
    "print(\"Synthetic columns preview:\", df_synth.columns.tolist()[:10])\n",
    "\n",
    "# Ensure categorical columns are numeric codes like original preprocessing (if needed)\n",
    "cat_cols = ['proto', 'service', 'state', 'attack_cat']\n",
    "for c in cat_cols:\n",
    "    if c in df_synth.columns and not np.issubdtype(df_synth[c].dtype, np.number):\n",
    "        df_synth[c] = df_synth[c].astype('category').cat.codes\n",
    "\n",
    "# Check required columns (top_features + label)\n",
    "miss = [c for c in top_features + ['label'] if c not in df_synth.columns]\n",
    "if miss:\n",
    "    raise KeyError(f\"Synthetic data is missing required columns: {miss}\")\n",
    "\n",
    "# Prepare X_synth / y_synth (using the same top_features as used for training)\n",
    "X_synth_raw = df_synth[top_features].copy()\n",
    "y_synth = df_synth['label'].astype(int).values\n",
    "\n",
    "# 1) Evaluate existing classifier (trained on real data) on synthetic data\n",
    "# note: `scaler` and `clf` come from earlier cells (scaler fitted on real X_train, clf trained on real)\n",
    "X_synth_scaled_with_real_scaler = scaler.transform(X_synth_raw)\n",
    "y_synth_pred_by_real_clf = clf.predict(X_synth_scaled_with_real_scaler)\n",
    "acc_synth_by_real_clf = accuracy_score(y_synth, y_synth_pred_by_real_clf)\n",
    "print(f\"Accuracy of real-trained classifier on synthetic data: {acc_synth_by_real_clf:.4f}\")\n",
    "\n",
    "# 2) Train classifier on synthetic data and evaluate on real test set\n",
    "# Prepare real test raw features (unscaled)\n",
    "X_test_raw = df_test[top_features].copy()\n",
    "# fit a new scaler on synthetic raw features\n",
    "scaler_synth = StandardScaler()\n",
    "X_synth_scaled = scaler_synth.fit_transform(X_synth_raw)\n",
    "X_test_scaled_by_synth = scaler_synth.transform(X_test_raw)\n",
    "\n",
    "clf_synth = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    random_state=42,\n",
    "    max_iter=200,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    verbose=False\n",
    ")\n",
    "clf_synth.fit(X_synth_scaled, y_synth)\n",
    "y_pred_from_synth_trained = clf_synth.predict(X_test_scaled_by_synth)\n",
    "acc_synth_trained_on_real_test = accuracy_score(y_test, y_pred_from_synth_trained)\n",
    "print(f\"Accuracy of synthetic-trained classifier evaluated on real test: {acc_synth_trained_on_real_test:.4f}\")\n",
    "\n",
    "# 3) Augment real training data with synthetic, retrain and evaluate on real test\n",
    "# Reconstruct real raw training features from df_train using top_features\n",
    "X_train_raw = df_train[top_features].copy()\n",
    "y_train_raw = df_train['label'].astype(int).values\n",
    "\n",
    "X_aug_raw = pd.concat([X_train_raw, X_synth_raw], ignore_index=True)\n",
    "y_aug = np.concatenate([y_train_raw, y_synth], axis=0)\n",
    "\n",
    "scaler_aug = StandardScaler()\n",
    "X_aug_scaled = scaler_aug.fit_transform(X_aug_raw)\n",
    "X_test_scaled_by_aug = scaler_aug.transform(X_test_raw)\n",
    "\n",
    "clf_aug = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    random_state=42,\n",
    "    max_iter=200,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    verbose=False\n",
    ")\n",
    "clf_aug.fit(X_aug_scaled, y_aug)\n",
    "y_pred_aug = clf_aug.predict(X_test_scaled_by_aug)\n",
    "acc_augmented = accuracy_score(y_test, y_pred_aug)\n",
    "print(f\"Accuracy after augmenting real training with synthetic (eval on real test): {acc_augmented:.4f}\")\n",
    "\n",
    "# Summarize\n",
    "print(\"\\nSummary of accuracies:\")\n",
    "print(f\"- Real-trained clf on real test (previously computed): {acc:.4f}\")\n",
    "print(f\"- Real-trained clf on synthetic data: {acc_synth_by_real_clf:.4f}\")\n",
    "print(f\"- Trained on synthetic only, eval on real test: {acc_synth_trained_on_real_test:.4f}\")\n",
    "print(f\"- Trained on real+synthetic (augmented), eval on real test: {acc_augmented:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
